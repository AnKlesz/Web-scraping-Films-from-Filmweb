{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scraping filmów z serwisu Filmweb**\n",
    "\n",
    "# 1\\. Wprowadzenie\n",
    "\n",
    "W moim projekcie zajmę się analizą preferencji użytkowników serwisu **Filmweb**. Chcę poznać jakie parametry mają decydujący wpływ na końcową ocenę filmu. Aby przeprowadzić takie badanie należy pozyskać odpowiednie dane, czyli informację o filmach z możliwie wieloma informacjami dostępnymi na stronie. Wśród tych danych można wyróżnić te za które odpowiadają użytkownicy serwisu i zależą od ich preferencji oraz aktywości jak na przykład średnia ocena, liczba ocen i liczba wątków na forum, oraz dane o filmie jak kraj, gatunek lub reżyser. Dodatkowo w serwisie występuje grupa krytyków filmowych, których recenzje są wyróżnice, a liczba ocen oraz średnia jest liczona oddzielnie.\n",
    "\n",
    "Aby uzyskać aktualne i możliwie kompletne dane wykorzystam scraping, czyli automatyczny proces przeszukiwania i pobierania informacji z Internetu. Dzięki samodzielnemu napisaniu służącego temu skryptu mogę zebrać wszystkie dane potencjalnie przydatne do analizy i następnie ewentualnie odrzucić je na dalszym etapie. Web scraping musi być poprzedzony zapoznaniem się ze strukturą strony, po której skrypt ma się poruszać. Należy poznać budowę i adresy podstron interesujących nas, znaleźć sprawny system nawigacji pomiędzy kolejnymi elementami oraz określić gdzie we fragmentach kodu HTML, CSS czy JavaScript znajdują się dane, które chcemy pobrać.\n",
    "\n",
    "Należy również pamiętać o tym że strony internetowe są na bieżąco rozwijane i w trakcie tworzenia lub używania algorytmu mogą zajść na nich zmiany wymuszające dostosowanie kodu. Duża aktualizacja może wręcz wymusić całkowite przepisanie skryptu. Problem ten pojawił się również podczas tego projektu, gdzie zmianie uległa struktura strony wyszukiwarki, używanej do poruszania się pomiędzy kolejnymi filmami. Dokładny opis zaistniałej sytuacji zawarłam poniżej."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Przygotowanie środowiska\n",
    "\n",
    "Na początku deklaruję wykorzystywane biblioteki. Dane z HTML będę pobierać za pomocą *requests* i następnie parsować je przy użyciu *BeautifulSoup*. Do zbierania danych w macierzy będzie służyła biblioteka numpy, aby przerobić je na DataFrame i wyeksportować do pliku CSV biblioteka *pandas*, a *random* oraz *time* posłużą odczekiwaniu między kolejnymi zapytaniami, aby uniknąć potencjalnego zablokowania przez serwis Filmweb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Poszukiwanie metody scrapowania Filmwebu\n",
    "\n",
    "Na początku należy przeanalizować możliwość scrapowania strony **filmweb.pl**. Strona z pojedynczym filmem ma adres jak poniżej:\n",
    "\n",
    "https://www.filmweb.pl/film/Sherlock+Holmes-2009-426062\n",
    "\n",
    "Widać, zatem że składa się on z 3 zmiennych, tytułu, roku premiery i ID filmu. Przechodzenie więc do filmów na przykład na podstawie losowania ID jest więc niemożliwe, ponieważ nie będę znać tytułu oraz roku. Należy więc odwiedzać kolejne strony poprzez przeszukiwanie zbiorczych stron z filmami. Pierwszą możliwością byłoby przeglądanie rankingu najlepszych filmów:\n",
    "\n",
    "https://www.filmweb.pl/ranking/film\n",
    "\n",
    "Jednakże na tej stronie jest tylko 500 najlepszych pozycji. Rankingi dla pojedynczych gatunków zwracają jeszcze mniej, bo jedynie 100 filmów, przykładowo:\n",
    "\n",
    "https://www.filmweb.pl/ranking/film/Akcja/28\n",
    "\n",
    "Aby móc dostać się do wszystkich dostępnych filmów, należy skorzystać z wyszukiwarki:\n",
    "\n",
    "https://www.filmweb.pl/films/search\n",
    "\n",
    "Pozwala ona na filtrowanie filmów po gatunkach, krajach, latach produkcji czy ocenach. Decyduję się, że będę przeszukiwała kolejne gatunki filmów w kolejności malejącej liczby ocen. W ten sposób przechodząc przez wszystkie istniejące w serwisie gatunki, zbiorę dane dotyczące wszystkich filmów. Najpierw należy jednak zdobyć listę wszystkich gatunków oraz numerów, które im odpowiadają w linku, jak przykładowo 28 dla filmów Akcji:\n",
    "\n",
    "https://www.filmweb.pl/search#/films?genres=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biograficzny', 'Dla dzieci', 'Dokumentalny', 'Dramat', 'Familijny', 'Surrealistyczny', 'Historyczny', 'Kostiumowy', 'Melodramat', 'Musical', 'Obyczajowy', 'Przygodowy', 'Sensacyjny', 'Western', 'Film-Noir', 'Komedia obycz.', 'Romans', 'Dramat obyczajowy', 'Psychologiczny', 'Satyra', 'Katastroficzny', 'Baśń', 'Polityczny', 'Muzyczny', 'Dreszczowiec', 'Czarna komedia', 'Krótkometrażowy', 'Religijny', 'Gangsterski', 'Biblijny', 'Dokumentalizowany', 'Komedia kryminalna', 'Dramat historyczny', 'Groteska filmowa', 'Sportowy', 'Poetycki', 'Szpiegowski', 'Dramat sądowy', 'Anime', 'Niemy', 'Fabularyzowany dok.', 'XXX', 'Sztuki walki', 'Przyrodniczy', 'Propagandowy', 'Animacja dla dorosłych', 'True crime', 'Afganistan', 'Albania', 'Algieria', 'Andora', 'Angola', 'Antigua i Barbuda', 'Arabia Saudyjska', 'Argentyna', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Autonomia Palestyńska', 'Azerbejdżan', 'Bahamy', 'Bahrajn', 'Bangladesz', 'Barbados', 'Belgia', 'Belize', 'Benin', 'Bhutan', 'Białoruś', 'Birma', 'Boliwia', 'Bośnia i Hercegowina', 'Botswana', 'Brazylia', 'Brunei', 'Bułgaria', 'Burkina Faso', 'Burundi', 'Chile', 'Chorwacja', 'Cypr', 'Czad', 'Czarnogóra', 'Czechosłowacja', 'Czechy', 'Demokratyczna Republika Konga', 'Dominika', 'Dominikana', 'Dżibuti', 'Egipt', 'Ekwador', 'Erytrea', 'Estonia', 'Etiopia', 'Fed. Rep. Jugosławii', 'Fidżi', 'Filipiny', 'Finlandia', 'Gabon', 'Gambia', 'Ghana', 'Grecja', 'Grenada', 'Grenlandia', 'Gruzja', 'Gujana', 'Gwadelupa', 'Gwatemala', 'Gwinea', 'Gwinea Bissau', 'Gwinea Równikowa', 'Haiti', 'Holandia', 'Honduras', 'Hongkong', 'Indonezja', 'Irak', 'Iran', 'Irlandia', 'Islandia', 'Izrael', 'Jamajka', 'Jemen', 'Jordania', 'Jugosławia', 'Kambodża', 'Kamerun', 'Kanada', 'Katar', 'Kazachstan', 'Kenia', 'Kirgistan', 'Kiribati', 'Kolumbia', 'Komory', 'Kongo', 'Korea', 'Korea Południowa', 'Korea Północna', 'Kosowo', 'Kostaryka', 'Kuba', 'Kuwejt', 'Laos', 'Lesotho', 'Liban', 'Liberia', 'Libia', 'Liechtenstein', 'Litwa', 'Luksemburg', 'Łotwa', 'Macedonia', 'Macedonia Północna', 'Madagaskar', 'Makau', 'Malawi', 'Malediwy', 'Malezja', 'Mali', 'Malta', 'Maroko', 'Martynika', 'Mauretania', 'Mauritius', 'Meksyk', 'Mikronezja', 'Mjanma', 'Mołdawia', 'Monako', 'Mongolia', 'Mozambik', 'Namibia', 'Nepal', 'Niemcy', 'Niger', 'Nigeria', 'Nikaragua', 'Niue', 'Norwegia', 'Nowa Zelandia', 'NRD', 'Oman', 'Pakistan', 'Palau', 'Palestyna', 'Panama', 'Papua Nowa Gwinea', 'Paragwaj', 'Peru', 'Portoryko', 'Portugalia', 'Republika Środkowoafrykańska', 'Republika Zielonego Przylądka', 'RFN', 'RPA', 'Ruanda', 'Rumunia', 'Sahara Zachodnia', 'Saint Lucia', 'Saint Vincent i Grenadyny', 'Salwador', 'Samoa', 'San Marino', 'Senegal', 'Serbia', 'Serbia i Czarnogóra', 'Seszele', 'Sierra Leone', 'Singapur', 'Słowacja', 'Słowenia', 'Somalia', 'Sri Lanka', 'Suazi', 'Sudan', 'Surinam', 'Syjam', 'Syria', 'Szwajcaria', 'Tadżykistan', 'Tajlandia', 'Tajwan', 'Tanzania', 'Togo', 'Tonga', 'Trynidad i Tobago', 'Tunezja', 'Turcja', 'Turkmenistan', 'Tuvalu', 'Uganda', 'Ukraina', 'Urugwaj', 'Uzbekistan', 'Vanuatu', 'Watykan', 'Wenezuela', 'Węgry', 'Wietnam', 'Wietnam Północny', 'Włochy', 'Wybrzeże Kości Słoniowej', 'Wyspy Marshalla', 'Wyspy Owcze', 'Zair', 'Zambia', 'Zimbabwe', 'Zjednoczone Emiraty Arabskie', 'ZSRR', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001', '2000', '1999', '1998', '1997', '1996', '1995', '1994', '1993', '1992', '1991', '1990', '1989', '1988', '1987', '1986', '1985', '1984', '1983', '1982', '1981', '1980', '1979', '1978', '1977', '1976', '1975', '1974', '1973', '1972', '1971', '1970', '1969', '1968', '1967', '1966', '1965', '1964', '1963', '1962', '1961', '1960', '1959', '1958', '1957', '1956', '1955', '1954', '1953', '1952', '1951', '1950', '1949', '1948', '1947', '1946', '1945', '1944', '1943', '1942', '1941', '1940', '1939', '1938', '1937', '1936', '1935', '1934', '1933', '1932', '1931', '1930', '1929', '1928', '1927', '1926', '1925', '1924', '1923', '1922', '1921', '1920', '1919', '1918', '1917', '1916', '1915', '1914', '1913', '1912', '1911', '1910', '1909', '1908', '1907', '1906', '1905', '1904', '1903', '1902', '1901', '1900', '1899', '1898', '1897', '1896', '1895', '1894', '1893', '1892', '1891', '1890', '1889', '1888']\n",
      "\n",
      "['3', '4', '5', '6', '8', '10', '11', '14', '16', '17', '19', '20', '22', '25', '27', '29', '32', '37', '38', '39', '40', '42', '43', '44', '46', '47', '50', '51', '53', '55', '57', '58', '59', '60', '61', '62', '63', '65', '66', '67', '70', '71', '72', '73', '76', '77', '80', '93', '135', '73', '146', '145', '155', '180', '2', '110', '181', '3', '4', '214', '122', '147', '158', '151', '157', '5', '154', '152', '153', '77', '112', '134', '96', '159', '6', '236', '78', '124', '160', '67', '9', '97', '182', '207', '68', '11', '211', '225', '116', '183', '95', '137', '184', '87', '143', '177', '185', '100', '14', '133', '223', '186', '18', '229', '164', '19', '163', '187', '119', '188', '175', '231', '81', '21', '189', '22', '98', '106', '25', '26', '27', '64', '117', '149', '165', '30', '167', '140', '31', '213', '128', '99', '190', '233', '82', '232', '118', '179', '91', '92', '205', '162', '33', '131', '113', '212', '94', '166', '109', '178', '88', '34', '107', '35', '239', '132', '192', '219', '220', '120', '129', '101', '105', '115', '125', '193', '36', '224', '238', '194', '111', '85', '80', '66', '72', '38', '195', '130', '168', '196', '39', '40', '71', '210', '102', '227', '148', '75', '142', '139', '41', '114', '43', '197', '161', '74', '44', '176', '89', '198', '230', '228', '199', '217', '200', '86', '206', '108', '201', '216', '46', '49', '76', '169', '126', '218', '170', '202', '203', '171', '47', '104', '90', '63', '127', '156', '209', '172', '50', '51', '173', '234', '174', '52', '83', '54', '235', '208', '57', '56', '65', '204', '61', '123', '226', '144', '121', '141', '79', '150', '62', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001', '2000', '1999', '1998', '1997', '1996', '1995', '1994', '1993', '1992', '1991', '1990', '1989', '1988', '1987', '1986', '1985', '1984', '1983', '1982', '1981', '1980', '1979', '1978', '1977', '1976', '1975', '1974', '1973', '1972', '1971', '1970', '1969', '1968', '1967', '1966', '1965', '1964', '1963', '1962', '1961', '1960', '1959', '1958', '1957', '1956', '1955', '1954', '1953', '1952', '1951', '1950', '1949', '1948', '1947', '1946', '1945', '1944', '1943', '1942', '1941', '1940', '1939', '1938', '1937', '1936', '1935', '1934', '1933', '1932', '1931', '1930', '1929', '1928', '1927', '1926', '1925', '1924', '1923', '1922', '1921', '1920', '1919', '1918', '1917', '1916', '1915', '1914', '1913', '1912', '1911', '1910', '1909', '1908', '1907', '1906', '1905', '1904', '1903', '1902', '1901', '1900', '1899', '1898', '1897', '1896', '1895', '1894', '1893', '1892', '1891', '1890', '1889', '1888']\n"
     ]
    }
   ],
   "source": [
    "# scrapowanie numerów odpowiadających gatunkom na Filmwebie z wyszukiwarki\n",
    "URL = \"https://www.filmweb.pl/ranking/film\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "genres_labels = soup.find_all(\"label\", class_=\"filterSelect__option fwBtn fwBtn--checkbox\")\n",
    "\n",
    "genres_list = []\n",
    "numbers_list = []\n",
    "\n",
    "for genre in genres_labels:\n",
    "    genre_name = genre[\"data-name\"]\n",
    "    number = genre[\"data-value\"]\n",
    "    genres_list.append(genre_name)\n",
    "    numbers_list.append(number)\n",
    "\n",
    "print(genres_list)\n",
    "print()\n",
    "print(numbers_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeszukując wszystkie opcje filtrowania filmów znalazłam, że są to kolejno gatunki, kraje produkcji oraz lata. Poniżej nazw filtrów wyświetliłam odpowiadające im numery, które pojawiają się w adresach stron. Ostatnim gatunkiem powinien być *True crime*, ponieważ dalej jest już pierwszy kraj, czyli *Afganistan*. Znajduję zatem na którym miejscu w liście jest ten gatunek i dla sprawdzenia wyświetlam wszystkie otrzymane gatunki. Do późniejszego użytku zapisuję zmienną *genres*, aby wiedzieć ile różnych gatunków jest w serwisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biograficzny; Dla dzieci; Dokumentalny; Dramat; Familijny; Surrealistyczny; Historyczny; Kostiumowy; Melodramat; Musical; Obyczajowy; Przygodowy; Sensacyjny; Western; Film-Noir; Komedia obycz.; Romans; Dramat obyczajowy; Psychologiczny; Satyra; Katastroficzny; Baśń; Polityczny; Muzyczny; Dreszczowiec; Czarna komedia; Krótkometrażowy; Religijny; Gangsterski; Biblijny; Dokumentalizowany; Komedia kryminalna; Dramat historyczny; Groteska filmowa; Sportowy; Poetycki; Szpiegowski; Dramat sądowy; Anime; Niemy; Fabularyzowany dok.; XXX; Sztuki walki; Przyrodniczy; Propagandowy; Animacja dla dorosłych; True crime; "
     ]
    }
   ],
   "source": [
    "genres = genres_list.index(\"True crime\") + 1\n",
    "for i in range(genres):\n",
    "    print (genres_list[i], end=\"; \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\\. Definiowanie funkcji\n",
    "\n",
    "Do przyszłego użytku definiuję funkcję **find_between** zwracającą string pomiędzy dwoma innymi stringami. Będzie ona przydatna przy scrapowaniu, ponieważ nie do wszystkich wiadomości można się dostać poprzez tagi HTML i CSS. Niektóre będę wyciągać z fragmentów adresów stron lub skryptów JavaScript widząc miedzy jakimi znakami się znajdują."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between(s, first, last):\n",
    "    try:\n",
    "        start = s.index(first) + len(first)\n",
    "        end = s.index(last, start)\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Głównym elementem kodu jest funkcja **filmweb_scraping**, która przyjmuje parametry *start_page* i *pages*, które odpowiadają za początkową stronę od której zacznę scraping i liczbę kolejnych stron do scrapowania. Dzięki temu mogę scrapować dane w kawałkach i co pewien czas eksportować do pliku CSV. Funckja bazuje na dwóch pętlach **for**, które iteruję po wszystkich gatunkach i po podanej przez nas liczbie stron w każdym z gatunków. W zmiennej *columns* zebrałam nagłówki dla przyszłego DataFrame, liczba tych nagłówków definiuje rozmiar macierzy *data*, do której będę dopisywać kolejne wiersze. W tym sposobie przeszukiwania serwisu natrafię na duplikaty, ponieważ film może mieć przypisanych kilka gatunków i wtedy pojawia się w wyszukiwarce w każdym z nich. Aby skrócić czas zbierania danych pobieram podczas scrapingu dane z pliku *filmweb.csv* do której eksportuję dane dotyczące filmów, aby sprawdzać czy dany film nie został już pobrany, na podstawie unikatowego ID. Sprawdzam również, czy film nie jest obecny w aktualnie tworzonej macierzy *data*. Używając pętli **for** z iteratorami *i* i *j* będę otwierać strony według poniższego f-stringu:\n",
    "\n",
    "`f\"https://www.filmweb.pl/films/search?genres={numbers_list[i]}&orderBy=count&descending=true&page={j}\"`\n",
    "\n",
    "Numery gatunków biorę z wcześniejszej listy *numbers_list*. Zawarcie w linku \"&orderBy=count&descending=true\" zapewnie że filmy będą posortowane według liczby ocen w kolejności malejącej. Ponieważ będę później skupiać się na analizie jak użytkownicy oceniają filmy, zakładam że film musi posiadać minimum 500 ocen, aby jego ocena była wiarygodna. Pozostałe filmy pomijam. Dodając do linku \"&page=\" otrzymuję konkretną stronę zawierającą 10 kolejnych filmów.\n",
    "\n",
    "***\n",
    "**UWAGA!**\n",
    "\n",
    "Od czasu wykonywania scrapingu (grudzień 2022) uległ zmianie format linków w wyszukiwarce oraz sposób generowania strony. Obecnie lista filmów w wyszukiwarce wyświetlana jest trybie infinite scroll i aby pobierać kolejne film należy wejść z nią w interakcję, na przykład za pomocą biblioteki *selenium*. Nowy link ma schemat:\n",
    "\n",
    "https://www.filmweb.pl/search#/films?genres=28&orderBy=count.desc&page=1\n",
    "\n",
    "Użycie fragmentu \"&page=\" nie wymusza jednak paginacji stron, a jedynie ogranicza ładowanie do 30 kolejnych filmów. Nadal cała interesująca nas zawartość generowana jest za pomocą JavaScriptu i nie da się jej pobrać w sposób jak wcześniej używając jedynie *requests* i *BeautifulSoup*. Wygląd poprzedniej strony wyszukiwarki z paginacją co 10 filmów można zobaczyć w serwisie The Wayback Machine:\n",
    "\n",
    "https://web.archive.org/web/20221223212507/https://www.filmweb.pl/films/search\n",
    "\n",
    "Aby dostosować algorytm do aktualnej budowy strony należałoby zmienić jedynie sposób przeszukiwania linków do kolejnych filmów. Dalsze działania, już na stronie filmu i stronie forum dotyczącego filmu, pozostają identyczne, ponieważ tam aktualnie (luty 2023) struktura kodu pozostała bez zmian.\n",
    "***\n",
    "\n",
    "Będąc na stronie wyszukiwarki znajduję zawarte na niej 10 filmów i tworzę z nich listę *results*, po której wykonuję kolejną iterację pętlą **for**. Na stronie wyszukiwarki są linki do każdego z 10 filmów, więc przechodzę do nich i parsuje je biblioteką *BeautifulSoup*, następnie przeszukując odpowiednie divy, spany, linki, nagłówki i skrypty i wyciągając z nich wszystkie interesujące mnie dane wymienione w liście *columns*. Lokalizacja potrzebnych informacji została znaleziona poprzez analizę budowy strony oraz metodą prób i błędów uruchamiając scraping aby znaleźć, które elementy nie pojawiają się dla każdego filmu jak budżet, scenarzysta, itp. Na koniec aby poznać liczbę wątków i odpowiedzi na wątki w forum dotyczącym filmu przechodzę pętlą **while** przez wszystkie strony forum sumując wątki i odpowiedzi. Pomiędzy kolejnymi filmami oraz stronami forum odczekuję losowy czas funckją **time.sleep** w połączeniu z **random**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ID\",\"Tytuł\",\"Tytuł org.\",\"Rok\",\"Długość\",\"Ocena\",\"Liczba ocen\",\"Najlepsza ocena\",\"Najgorsza ocena\",\\\n",
    "            \"Chce zobaczyć\",\"Ocena krytyków\",\"Liczba ocen krytyków\",\"Reżyser\",\"Scenariusz\",\"Gatunek\",\"Kraj\",\"Box Office\",\"Budżet\",\\\n",
    "            \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"Wątki\",\"Odpowiedzi\"]\n",
    "\n",
    "def filmweb_scraping(start_page, pages):\n",
    "    # pobieranie aktualnego pliku csv do pomijania duplikatów\n",
    "    existing_data = pd.read_csv('filmweb.csv', encoding='utf-8', header=None, sep=';')\n",
    "\n",
    "    # tworzenie macierzy o wymiarze 1 x liczba kolumn do zbierania danych\n",
    "    data = np.array([[0]*len(columns)])\n",
    "    # iterator pomocniczy do wyświetlania numeru aktualnie pobieranego filmu\n",
    "    iter = 0\n",
    "\n",
    "    # pętla po wszystkich gatunkach\n",
    "    for i in range(genres):\n",
    "        less_than_500_count = False # zmienna zapisująca czy doszłam do filmów poniżej 500 ocen w danym gatunku\n",
    "        \n",
    "        # pętla po kilku (pages) stronach najpopularniejszych\n",
    "        for j in range(start_page, pages + start_page):\n",
    "            \n",
    "            # przejście do kolejnego gatunku jeżeli w aktualnym gatunku kolejne filmy mają mniej niż 500 ocen\n",
    "            if less_than_500_count == True:\n",
    "                break\n",
    "            \n",
    "            # otwieranie kolejnych linków filmami w danym gatunku według liczby ocen malejąco\n",
    "            URL = f\"https://www.filmweb.pl/films/search?genres={numbers_list[i]}&orderBy=count&descending=true&page={j}\"\n",
    "            page = requests.get(URL)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            # wyciąganie 10 filmów ze strony\n",
    "            results = soup.find_all(\"div\",class_=\"preview previewCard previewFilm PreviewFilm\")\n",
    "            # przejście do kolejnego gatunku jeżeli strona jest pusta\n",
    "            if results == None:\n",
    "                break\n",
    "\n",
    "            for result in results:                \n",
    "                iter += 1\n",
    "                \n",
    "                # szukanie linku do filmu i otwieranie go jako nowy request\n",
    "                link_element = result.find(\"div\", class_=\"poster__wrapper\")\n",
    "                link = link_element.find(\"a\")\n",
    "                film_url = \"https://www.filmweb.pl\" +link[\"href\"]\n",
    "                film_page = requests.get(film_url)\n",
    "                film_soup = BeautifulSoup(film_page.content, \"html.parser\")\n",
    "                \n",
    "                # pobieranie danych tytuł, rok, długość\n",
    "                title_data = film_soup.find(\"div\", class_=\"filmCoverSection__fP film\")\n",
    "                id = title_data[\"data-film-id\"]\n",
    "                title = title_data.find(\"h1\").text\n",
    "                year = title_data.find(\"div\", class_=\"filmCoverSection__year\").text\n",
    "                \n",
    "                # sprawdzanie czy film nie jest już w filmweb.csv (pandas - trzeba wybrać '.values') \n",
    "                # aktualnym zbiorze (numpy - konflikt porówywania, trzeba wymusić typ int dla obu stron)\n",
    "                if int(id) in existing_data.iloc[:,0].values or int(id) in data[:,0].astype(int):\n",
    "                    print(f\"{iter}. {title} ({genres_list[i]}) - duplikat!\")\n",
    "                    continue\n",
    "                \n",
    "                # sprawdzanie czy premiera przed 2023 + wyświetlanie aktualnie przetwarzanego filmu\n",
    "                elif int(year) > 2022:\n",
    "                    print(f\"{iter}. {title} ({genres_list[i]}) - przed premierą!\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"{iter}. {title} ({genres_list[i]})\")\n",
    "\n",
    "                # original_title może nie być, wtedy jest jak title                    \n",
    "                original_title_div = title_data.find(\"div\", class_=\"filmCoverSection__originalTitle\")\n",
    "                if original_title_div == None:\n",
    "                    original_title = title\n",
    "                else:\n",
    "                    original_title = original_title_div.text\n",
    "                    \n",
    "                # pobieranie długości filmu\n",
    "                try:\n",
    "                    watch_time_str = title_data.find(\"div\", class_=\"filmCoverSection__duration\")\n",
    "                    watch_time = watch_time_str[\"data-duration\"]\n",
    "                except:\n",
    "                    watch_time = \"N/A\"\n",
    "                \n",
    "                # pobieranie danych dot. ocen, jeżeli mniej niż 500 pomijam kolejne filmy w tym gatunku\n",
    "                try:\n",
    "                    rate_data = film_soup.find(\"div\", class_=\"page__container filmCoverSection__ratings afterPremiere\")\n",
    "                    rate_str = rate_data.find(\"div\", class_=\"filmRating filmRating--hasPanel\")\n",
    "                    rate = rate_str[\"data-rate\"]\n",
    "                    rating_count = rate_str[\"data-count\"]\n",
    "                    if int(rating_count) < 500:\n",
    "                        less_than_500_count = True\n",
    "                        break\n",
    "                except:\n",
    "                    less_than_500_count = True\n",
    "                    break\n",
    "                \n",
    "                # pobieranie najlepszej, najgorszej oceny i ile osób chce zobaczyć film\n",
    "                best_rating = rate_data.find(\"span\", itemprop=\"bestRating\").text\n",
    "                worst_rating = rate_data.find(\"span\", itemprop=\"worstRating\").text\n",
    "                want_to_see_str = rate_data.find_all(\"div\", class_=\"filmRating__rate\")\n",
    "                want_to_see1 = want_to_see_str[1].text\n",
    "                want_to_see = int(''.join(filter(str.isdigit, want_to_see1))) \n",
    "                \n",
    "                # pobieranie ocen krytyków\n",
    "                try:\n",
    "                    critics = str(rate_data.find(\"script\"))\n",
    "                    critics_rate = find_between(critics,'\"criticRatingData\",{rate:',\",\")\n",
    "                    critics_rating_count = find_between(critics,',count:',\"}\")\n",
    "                except:\n",
    "                    critics_rate = \"N/A\"\n",
    "                    critics_rating_count = 0\n",
    "\n",
    "                # pobieranie pozostałych danych\n",
    "                try:\n",
    "                    director = film_soup.find(\"div\", {\"data-type\": \"directing-info\"}).text\n",
    "                except:\n",
    "                    director = \"N/A\"\n",
    "                try:\n",
    "                    screenwriting = film_soup.find(\"div\", {\"data-type\": \"screenwriting-info\"}).text\n",
    "                except:\n",
    "                    screenwriting = \"N/A\"\n",
    "                try:\n",
    "                    boxoffice_str = film_soup.find(\"div\", class_=\"boxoffice\").text\n",
    "                    boxoffice = int(\"\".join(find_between(boxoffice_str,\"$\",\" w USA\").split()))\n",
    "                except:\n",
    "                    boxoffice = \"N/A\"\n",
    "                    \n",
    "                # pobieranie gatunku i kraju\n",
    "                genre_div = film_soup.find(\"div\", itemprop=\"genre\")\n",
    "                genre = genre_div.find(\"a\").text\n",
    "                country_div = film_soup.find(\"div\", class_=\"filmPosterSection__info filmInfo\")\n",
    "                country_str = find_between(str(country_div),'produkcja</h3><div class=\"filmInfo__info\"><span> <a href=\"/ranking/film/',\"/\")\n",
    "                country = country_str.replace(\"+\",\" \") # w linku jest + zamiast spacji\n",
    "\n",
    "                try:\n",
    "                    budget_div = film_soup.find(\"div\", class_=\"filmOtherInfoSection__group\")\n",
    "                    budget = int(\"\".join(find_between(str(budget_div),'<div class=\"filmInfo__header\">budżet</div><div class=\"filmInfo__info\">$',\"</\").split()))  \n",
    "                except:                \n",
    "                    budget=\"N/A\"\n",
    "                \n",
    "                film_data = [id,title,original_title,year,watch_time,rate,rating_count,best_rating,\n",
    "                                    worst_rating,want_to_see,critics_rate,critics_rating_count,\n",
    "                                    director,screenwriting,genre,country,boxoffice,budget]\n",
    "\n",
    "                # znalezienie skryptu wyświetlającego ile film dostał ocen 1, 2, ..., 10 i dopisanie do film_data\n",
    "                for item in film_soup.find_all(\"script\"):\n",
    "                    if '\"filmRating\"' in item.text:\n",
    "                        for rating in range(10):\n",
    "                            film_data = np.append(film_data,(find_between(item.text,f'\",countVote{rating + 1}:\"','\"')))\n",
    "                            \n",
    "                # szukanie linku do forum i otwieranie go jako nowy request\n",
    "                discussion_url = film_url + \"/discussion\"\n",
    "                discussion_page = requests.get(discussion_url)\n",
    "                discussion_soup = BeautifulSoup(discussion_page.content, \"html.parser\")\n",
    "\n",
    "                reply_count = 0\n",
    "                threat_count = 0\n",
    "\n",
    "                next_page = discussion_soup.find(\"a\", title=\"następna\")\n",
    "\n",
    "                while next_page is not None:\n",
    "                    comments = discussion_soup.find_all(\"span\", class_=\"forumSection__commentsCount\")\n",
    "                    threat_count = threat_count + len(discussion_soup.find_all(\"div\", class_=\"forumSection__topRow\"))\n",
    "                    for comment in comments:\n",
    "                        reply_count = reply_count + int(comment.text)\n",
    "                    discussion_page = requests.get(\"https://www.filmweb.pl\" + next_page[\"href\"])\n",
    "                    discussion_soup = BeautifulSoup(discussion_page.content, \"html.parser\")\n",
    "                    next_page = discussion_soup.find(\"a\", title=\"następna\")\n",
    "                    time.sleep(random()/20)\n",
    "                else:\n",
    "                    try:\n",
    "                        comments = discussion_soup.find_all(\"span\", class_=\"forumSection__commentsCount\")\n",
    "                        threat_count = threat_count + len(discussion_soup.find_all(\"div\", class_=\"forumSection__topRow\"))\n",
    "                        for comment in comments:\n",
    "                            reply_count = reply_count + int(comment.text)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # dodanie danych o wątkach i odpowiedziach\n",
    "                film_data = np.append(film_data,[threat_count,reply_count])           \n",
    "\n",
    "                # dodawanie danych do listy jako kolejny wiersz\n",
    "                data = np.append(data,[film_data],axis=0)\n",
    "                                                \n",
    "                # czyszczenie zmiennych\n",
    "                del id,title,original_title,year,watch_time,rate,rating_count,best_rating,\\\n",
    "                    worst_rating,want_to_see,critics_rate,critics_rating_count,\\\n",
    "                    director,screenwriting,genre,country,boxoffice,budget,threat_count,reply_count\n",
    "\n",
    "                time.sleep(random()/10)\n",
    "    \n",
    "    # zwrócenie macierzy numpy \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższa funkcja **data_to_dataframe** służy przejścia z macierzy *numpy* na DataFrame *pandas*. Dodatkowo usuwam pierwszy wiersz, które wcześniej wypełniłam zerami, aby zainicjować macierz w odpowiednim rozmiarze. Przypisuję również nazwy kolumn ze zmiennej *columns*.\n",
    "\n",
    "Funckja **update_csv** dopisuje do naszego pliku zbiorczego kolejne wiersze bez nagłówków z ustalonym separatorem \";\" który nie pojawia się w przeciwieństwie do \",\" żadnych danych.\n",
    "\n",
    "Funckja **backup_csv** służy do odczytu aktulnego pliku zbiorczego CSV i zapisu go do pliku CSV w którym dodaję nagłówki i aktualny czas do nazwy pliku, aby dostać unikatowy plik kopii zapasowej wywołując ją co pewien czas w głównej pętli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_dataframe(data):\n",
    "    if data[0, 0] == \"0\":\n",
    "        data = np.delete(data, obj=0, axis=0)\n",
    "    df = pd.DataFrame(data=data[0:, 0:], index=[i + 1 for i in range(data.shape[0])], columns=columns)\n",
    "    return df\n",
    "\n",
    "def update_csv(df):\n",
    "    df.to_csv(\"filmweb.csv\", mode=\"a\", encoding=\"utf-8\", index=False, header=False, sep=\";\")\n",
    "    \n",
    "def backup_csv():\n",
    "    df = pd.read_csv(\"filmweb.csv\", encoding=\"utf-8\", header=None, names=columns, sep=\";\")\n",
    "    df.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
    "    df.to_csv(\n",
    "        f'filmweb_{time.strftime(\"%Y%m%d-%H%M%S\")}.csv',\n",
    "        encoding=\"utf-8\",\n",
    "        index=False,\n",
    "        header=columns,\n",
    "        sep=\";\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się główna pętla programu, która przechodząc przez strony 1-999 co *pages*=10 stron zbiera dane za pomocą funkcji **filmweb_scraping**. Po wykonaniu tej funkcji dane zamieniane na DataFrame poprzez **data_to_dataframe** oraz zapisywane do pliku CSV poprzez **update_csv**. Dodatkowo co 50 stron zapisuję dane do osobnego pliku używając **backup_csv**. Za pomocą **try** i **except** zbieram informacje na temat ewentualnych błędów w scrapingu i miejsca wystąpienia błędu, co pozwala na określenie miejsca do którego informacje zostały pobrane poprawnie i ponowne puszczenie funkcji od wskazanej strony po dostosowaniu kodu. Na koniec wczytuję ukończony plik CSV i zapisuję go z nagłówkami *columns*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Man in the Wolf Mask (Biograficzny)\n",
      "2. Zarifa Ghafari: Wszystko w jej rękach (Dokumentalny)\n",
      "3. Ballada o Narayamie (Dramat) - duplikat!\n",
      "4. Wiem, że na imię mam Steven (Dramat) - duplikat!\n",
      "5. Szkoda twoich łez (Dramat) - duplikat!\n",
      "6. Ugór (Dramat) - duplikat!\n",
      "7. 90 minutter (Dramat) - duplikat!\n",
      "8. To my, a to ja (Dramat) - duplikat!\n",
      "9. Prawdziwe kobiety są zaokrąglone (Dramat) - duplikat!\n",
      "10. Poongsan (Dramat) - duplikat!\n",
      "11. Sala numer 6 (Dramat) - duplikat!\n",
      "12. Dlaczego Pan R. oszalał? (Dramat) - duplikat!\n",
      "13. Sierota (Dramat) - duplikat!\n",
      "14. Stalin (Dramat) - duplikat!\n",
      "15. Mój koniec. Twój początek (Dramat) - duplikat!\n",
      "16. Ciotka Hitlera (Dramat) - duplikat!\n",
      "17. Szczury (Dramat) - duplikat!\n",
      "18. Lick the Star (Dramat) - duplikat!\n",
      "19. Pod oliwkami (Dramat) - duplikat!\n",
      "20. Ali się żeni (Dramat) - duplikat!\n",
      "21. The Bad Mother's Handbook (Dramat) - duplikat!\n",
      "22. Mój problem to ty (Dramat) - duplikat!\n",
      "23. Uczniowie zmieniają świat (Dramat) - duplikat!\n",
      "24. Szczęście na raty (Dramat) - duplikat!\n",
      "25. Składanka (Dramat) - duplikat!\n",
      "26. Architekt (Dramat) - duplikat!\n",
      "27. Metropolitan (Dramat) - duplikat!\n",
      "28. Zderzenie (Dramat) - duplikat!\n",
      "29. Gwiazdka (Dramat) - duplikat!\n",
      "30. Spalone (Dramat) - duplikat!\n",
      "31. Georgia O'Keeffe (Dramat) - duplikat!\n",
      "32. Żona bogatego mężczyzny (Dramat) - duplikat!\n",
      "33. Love Aaj Kal (Dramat) - duplikat!\n",
      "34. Dzień w Juriewie (Dramat) - duplikat!\n",
      "35. Aż na koniec świata (Dramat) - duplikat!\n",
      "36. Wieczna poezja (Dramat) - duplikat!\n",
      "37. Gwiazda (Dramat) - duplikat!\n",
      "38. Mój przyjaciel Smitty (Dramat) - duplikat!\n",
      "39. Harmider (Dramat) - duplikat!\n",
      "40. Trudno być Bogiem (Dramat) - duplikat!\n",
      "41. Król Kreol (Dramat) - duplikat!\n",
      "42. Ja kocham, ty kochasz (Dramat) - duplikat!\n",
      "43. Zanim znikniemy (Dramat) - duplikat!\n",
      "44. Dokąd zmierzasz? (Dramat) - duplikat!\n",
      "45. Zero moskiewskie (Dramat) - duplikat!\n",
      "46. Nastolatki (Dramat) - duplikat!\n",
      "47. Deklaracja (Dramat) - duplikat!\n",
      "48. Śmiertelne manewry (Dramat) - duplikat!\n",
      "49. Sam się nie uratujesz (Dramat) - duplikat!\n",
      "50. Miasto ucieczki (Dramat) - duplikat!\n",
      "51. W uchu cisza (Dramat) - duplikat!\n",
      "52. Milarepa (Dramat) - duplikat!\n",
      "53. Takie są zasady (Dramat) - duplikat!\n",
      "54. Zabójstwo (Dramat) - duplikat!\n",
      "55. Łabędzi śpiew (Dramat) - duplikat!\n",
      "56. Zakładnik (Dramat) - duplikat!\n",
      "57. Zima, która odmieniła moje życie (Dramat) - duplikat!\n",
      "58. Marcel Muszelka w różowych bucikach (Dramat) - duplikat!\n",
      "59. Stroiciel trzęsień ziemi (Dramat) - duplikat!\n",
      "60. Pobij diabła (Dramat) - duplikat!\n",
      "61. Zmierzch długiego dnia (Dramat) - duplikat!\n",
      "62. On my Mind (Dramat) - duplikat!\n",
      "63. Koszmary (Dramat) - duplikat!\n",
      "64. Meantime (Dramat) - duplikat!\n",
      "65. Gasnący płomień (Dramat) - duplikat!\n",
      "66. Brotherhood (Dramat) - duplikat!\n",
      "67. Nadzy (Dramat) - duplikat!\n",
      "68. Twarda sztuka (Dramat) - duplikat!\n",
      "69. Co mówią lekarze (Dramat) - duplikat!\n",
      "70. Wschodni Sztokholm (Dramat) - duplikat!\n",
      "71. Wojownik (Dramat) - duplikat!\n",
      "72. Ostatnia gwiazda kina (Dramat) - duplikat!\n",
      "73. Bajrangi Bhaijaan (Dramat)\n",
      "74. Dziewczyny inne niż wszystkie (Dramat)\n",
      "75. Pinokio - Opowieść o chłopcu z drewna (Dramat) - duplikat!\n",
      "76. Hotel Normandy (Dramat)\n",
      "77. Ciche wesele (Dramat)\n",
      "78. Tai-Pan (Dramat) - duplikat!\n",
      "79. Paraísos Artificiais (Dramat)\n",
      "80. Semper Fi (Dramat)\n",
      "81. Piekło '63 (Dramat) - duplikat!\n",
      "82. Lykkevej (Dramat)\n",
      "83. Dzielnica pięciu narożników (Dramat) - duplikat!\n",
      "84. Święto zmarłych (Dramat) - duplikat!\n",
      "85. Tragedia w trzech aktach (Dramat) - duplikat!\n",
      "86. Audrey Rose (Dramat) - duplikat!\n",
      "87. Code Geass: Hangyaku no Lelouch R2 Special Edition 'Zero Requiem' (Dramat) - duplikat!\n",
      "88. Sea Wall (Dramat) - duplikat!\n",
      "89. W gorączce (Dramat) - duplikat!\n",
      "90. Kurbaan (Dramat) - duplikat!\n",
      "91. Ojciec i syn (Dramat) - duplikat!\n",
      "92. Vocuus (Dramat) - duplikat!\n",
      "93. Ostrze włóczni (Dramat) - duplikat!\n",
      "94. Dziewczyny (Dramat) - duplikat!\n",
      "95. Whisky (Dramat) - duplikat!\n",
      "96. Kobiety czekają (Dramat) - duplikat!\n",
      "97. Biały żołnierz (Dramat) - duplikat!\n",
      "98. Porwanie (Dramat) - duplikat!\n",
      "99. Pogrzeb świerszcza (Dramat) - duplikat!\n",
      "100. Zwrot (Dramat) - duplikat!\n",
      "101. Remember the Daze (Dramat) - duplikat!\n",
      "102. Żona sąsiada (Dramat) - duplikat!\n",
      "103. Big Ears (Familijny)\n",
      "104. Ek Cup Cha (Melodramat)\n",
      "105. L'Attaque du monstre géant suceur de cerveaux de l'espace (Musical)\n",
      "106. Pojedynek ognia (Przygodowy)\n",
      "107. The Boss of the Lazy Y (Western)\n",
      "108. De wraak van het visschersmeisje (Romans)\n",
      "109. The Adventures of Jack Uzi: Long Hard Days (Muzyczny)\n",
      "110. Sepultura: We Are What We Are (Krótkometrażowy)\n",
      "111. Boerenidylle (Niemy)\n",
      "1. AP Sports Basketball - Vol. 1: Isiah Thomas (Biograficzny)\n",
      "2. NBA prosto z ulicy: Czarodzieje Boiska cz. 2 (Dokumentalny)\n",
      "3. Brzmienie ciszy (Dramat) - duplikat!\n",
      "4. Laleczka (Dramat) - duplikat!\n",
      "5. Madeline i Madeline (Dramat) - duplikat!\n",
      "6. Nad przepaścią (Dramat) - duplikat!\n",
      "7. The Details (Dramat) - duplikat!\n",
      "8. Czułość (Dramat) - duplikat!\n",
      "9. Fair Play (Dramat) - duplikat!\n",
      "10. Bare (Dramat) - duplikat!\n",
      "11. M. (Dramat) - duplikat!\n",
      "12. Buba (Dramat) - duplikat!\n",
      "13. Siedlisko węży (Dramat)\n",
      "14. Wyrok należy do nas (Dramat)\n",
      "15. Najsmutniejsza muzyka świata (Dramat) - duplikat!\n",
      "16. Kroniki zagłady (Dramat)\n",
      "17. Ponad niebem (Dramat) - duplikat!\n",
      "18. Molo (Dramat) - duplikat!\n",
      "19. Młoda dziewczyna (Dramat) - duplikat!\n",
      "20. Eloïse (Dramat)\n",
      "21. Wielka nagroda (Dramat) - duplikat!\n",
      "22. W poszukiwaniu idealnego kochanka (Dramat)\n",
      "23. Czarne i białe (Dramat) - duplikat!\n",
      "24. Tłumacz (Dramat)\n",
      "25. Człowiek z pociągu (Dramat)\n",
      "26. Obcym wstęp wzbroniony (Dramat)\n",
      "27. Czasem, zawsze, nigdy (Dramat)\n",
      "28. Zdążyć przed chłodem (Dramat)\n",
      "29. Samui Song (Dramat)\n",
      "30. Pustynia Tatarów (Dramat)\n",
      "31. W poniedziałek rano (Dramat) - duplikat!\n",
      "32. Parking (Dramat)\n",
      "33. Córki (Dramat)\n",
      "34. Bunny (Dramat) - duplikat!\n",
      "35. Suk Suk (Dramat)\n",
      "36. Między ludźmi (Dramat)\n",
      "37. Podróż z tatą (Dramat)\n",
      "38. I Am Not a Hipster (Dramat) - duplikat!\n",
      "39. Wszystkie drogi prowadzą do domu (Dramat) - duplikat!\n",
      "40. Podróżnicy i magowie (Dramat) - duplikat!\n",
      "41. Zbrodnie serca (Dramat)\n",
      "42. Bractwo sprawiedliwych (Dramat)\n",
      "43. Femina (Dramat) - duplikat!\n",
      "44. Zmiana planów (Dramat) - duplikat!\n",
      "45. Kto leży w moim grobie? (Dramat)\n",
      "46. Rajskie ptaki (Dramat)\n",
      "47. Uśpiony głos (Dramat)\n",
      "48. A Gentleman's Gentleman (Familijny)\n",
      "49. Saturday's Heroes (Melodramat)\n",
      "50. Nunsense 2: The Sequel (Musical)\n",
      "51. Jy is my liefling (Przygodowy)\n",
      "52. Texas (Western)\n",
      "53. Tyomnaya noch (Romans)\n",
      "54. Comedy Is King (Muzyczny)\n",
      "55. The Song of Avila (Krótkometrażowy)\n",
      "56. Excuse My Dust (Niemy)\n",
      "1. Der Maler mit dem Stern (Biograficzny)\n",
      "2. Jackson Pollock (Dokumentalny)\n",
      "3. Dolegliwości (Dramat)\n",
      "4. Mega Mindy Versus ROX (Familijny)\n",
      "5. Tierra de pasiones (Melodramat)\n",
      "6. Renukadevi Mahatyam (Musical)\n",
      "7. Ci man wang (Przygodowy)\n",
      "8. Target (I) (Western)\n",
      "9. Der Große Bluff (Romans)\n",
      "10. Yo soy, del Son a la Salsa (Muzyczny)\n",
      "11. Uncle Josh in a Spooky Hotel (Krótkometrażowy)\n",
      "12. Barrabas (Niemy)\n",
      "1. After Ever After or Numbers on a Napkin (Biograficzny)\n",
      "2. Powiedz mi (Dokumentalny)\n",
      "3. Sjesta (Dramat)\n",
      "4. Wolf! Wolf! (Familijny)\n",
      "Błąd na stronie nr 760\n",
      "1. Sami Hazinses belgeseli (Biograficzny)\n",
      "2. Roznosiciele radości (Dokumentalny)\n",
      "3. Dziewczynka (Dramat)\n"
     ]
    }
   ],
   "source": [
    "pages = 10\n",
    "for start_page in range (1, 999, pages):\n",
    "    try:\n",
    "        data = filmweb_scraping(start_page, pages)\n",
    "        df = data_to_dataframe(data)\n",
    "        update_csv(df)\n",
    "        #zapis do nowego pliku co 50 stronę\n",
    "        if ((start_page > 1) & (start_page % 50 == 1)):\n",
    "            backup_csv()\n",
    "    except:\n",
    "        print(f\"Błąd na stronie nr {start_page}\")\n",
    "\n",
    "df = pd.read_csv(\"filmweb.csv\", encoding=\"utf-8\", header=None, names=columns, sep=\";\")\n",
    "df.to_csv('filmweb.csv', encoding=\"utf-8\", index=False, header=columns, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c886c914bdf3e78a632b7220e5c8f06a0e7ae3de9caa887206fd3781da1fcc3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
